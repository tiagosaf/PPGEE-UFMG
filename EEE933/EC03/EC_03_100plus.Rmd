---
title: "PPGEE UFMG - EEE933 - Estudo de Caso 03 (SOLUÇÃO COMPLEMENTAR)"
author: |
  | Equipe 3
  | (Verificadora) Amanda Fernandes Vilaça Martins, (Relator) Bruno Marciano Lopes, 
  | (Monitor) Igor Almeida Baratta, (Coordenador) Tiago de Sá Ferreira
date: "10 de outubro de 2016"
output: pdf_document
---

---
references:
- id: campelo2015
  title: Lecture Notes on Design and Analysis of Experiments (Version 2.11; Creative Commons BY-NC-SA 4.0)
  author:
  - family: Campelo
    given: Felipe
  URL: http://git.io/v3Kh8
  publisher: Website
  page: Acesso em 08/set/2016
  type: article-journal
  issued:
    year: 2015

- id: campelo2016
  title: Classification Algorithms Experiment - Simulator
  author:
  - family: Campelo
    given: Felipe
  URL: http://orcslab.cpdee.ufmg.br:3838/classdata/
  publisher: Website
  page: Acesso em 04/out/2016
  type: article-journal
  issued:
    year: 2016
    
- id: nordheim2003
  title: 7.6.2 Appendix - Using R to Find Confidence Intervals
  author:
  - family: Nordheim
    given: EV
  - family: Clayton
    given: MK
  - family: Yandell
    given: BS   
  URL: https://www.stat.wisc.edu/~yandell/st571/R/append7.pdf
  publisher: Website
  page: Acesso em 04/out/2016
  type: article-journal
  issued:
    year: 2003
---

```{r, include=FALSE}
if(!require(TeachingDemos)){
	install.packages("TeachingDemos")
	library(TeachingDemos)
}
if(!require(knitr)){
	install.packages("knitr")
}
if(!require(rmarkdown)){
	install.packages("rmarkdown")
}

if(!require(car)){
	install.packages("car")
}
if(!require(pwr)){
	install.packages("pwr")
}

if(!require(lmtest)){
	install.packages("lmtest")
}

if(!require(lsr)){
	install.packages("lsr")
  library(lsr)
}

if(!require(gplots)){
	install.packages("gplots")
  library(lsr)
}

# Limpa as variáveis armazenadas no workspace
rm(list = ls())

# Limpa o console
cat("\014") 
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Planejamento do experimento
### Características desejadas para os testes estatísticos
```{r}
alpha <- 0.05
PI <- 0.8
beta <- 1 - PI
dt <- 1
delta_a <- 0.03
n_rep <- 30
n_t <- 8
```

### Definição do número de amostras necessárias para o teste da acurácia
Para o teste referente à acurácia, para definir o número de instâncias $n_a$ considerando a potência desejada de $\Pi = 0.8$, é necessário conhecer $\sigma_{aS}$ e $\sigma_{aP}$. As variâncias (e os desvios padrões) das acurácias dos algoritmos são parâmetros desconhecidos. No entanto, uma vez que já se possui um número de instâncias calculado para o teste do tempo, os dados gerados com $n_t$ instâncias podem ser utilizados para estimar as variâncias das acurácias.

Dessa forma, uma primeira execução do aplicativo [@campelo2016] gerou os dados consolidados no arquivo "*1991-09-15_8_30.csv*".

```{r}
dados_preteste <- read.table("1991-09-15_8_30.csv",sep = ",", header = TRUE)

# Avalia as oito instâncias definidas para o teste do tempo
dados_inicial <- head(dados_preteste,2*n_t*n_rep)
dados_ac_pre <- aggregate(Accuracy~Algorithm:Instance, data=dados_inicial, FUN=mean)
summary(dados_ac_pre)
```

A partir dessa base de dados, estima-se a variância amostral das acurácias dos algoritmos. Utilizando uma abordagem mais conservadora, ao invés de utilizar os valores calculados como variâncias das acurácias, serão considerados nos testes os maiores valores de variância assumindo um intervalo de confiança utilizando o mesmo nível de significância já mencionado. Assim, assumindo que as distribuições das variâncias são normais, tem-se por [@nordheim2003] que:

```{r}
s2_interval = function(data, significance.level){
  df <- length(data) - 1
  chilower <- qchisq(significance.level/2, df)
  chiupper <- qchisq(significance.level/2, df, lower.tail = FALSE)
  v = var(data)
  c(df*v/chiupper,df*v/chilower)
}
```

A maior variância considerada da acurácia $S^2_{aPcon,max}$ do algoritmo simplificado proposto é:

```{r}
s2_aPcon_max <- max(s2_interval(dados_ac_pre$Accuracy[dados_ac_pre$Algorithm=="Proposed"],
                                alpha))
cat("s2_aPcon_max  =",s2_aPcon_max)
```

A maior variância considerada da acurácia $S^2_{aScon,max}$ do algoritmo padrão original é:
```{r}
s2_aScon_max = max(s2_interval(dados_ac_pre$Accuracy[dados_ac_pre$Algorithm=="Standard"],
                               alpha))
cat("s2_aScon_max  =",s2_aScon_max)
```

Para o teste de hipotése da acurácia será utilizada o método TOST, onde o teste será quebrado em dois testes-t unilaterais, e portanto será utilizada a função calcN\_tost2  [@campelo2015]. Para se obter pelo menos a potência $\Pi = 0.8$ no teste referente à acurácia, considerando amostras de tamanhos iguais para ambos os algoritmos, o número de instâncias $n_a$ do teste pode ser determinado através de:

```{r, include=FALSE}
# Felipe Campelo (2015), Lecture Notes on Design and Analysis of Experiments. 
# Online: http://git.io/v3Kh8 Version 2.11; Creative Commons BY-NC-SA 4.0.
# 
# Function to calculate sample size for 2-sample TOST, assuming n1=n2=n
# Based on Zhang (2003), Journal of Biopharmaceutical Statistics 13(3):529-538,
# modified for unequal variances
calcN_tost2<-function(alpha = 0.05, # significance level
                      beta = 0.2,    # type-II error rate
                      diff_mu = 0,   # maximum real difference |mu1-mu2| for 
                      # which a power (1-beta) is desired
                      tolmargin,     # tolerance margin (>0)
                      s1,            # estimated sd of first population
                      s2)            # estimated sd of second population
  # (defaults to s2=s1)
{
  # Function to calculate DoF for a t distribution using the Welch formula
  calc_df<-function(s1,s2,n1,n2)
  {(s1^2/n1 + s2^2/n2)^2/((s1^2/n1)^2/(n1-1) + (s2^2/n2)^2/(n2-1))}
  
  # Assume equality of variances if s2 is not informed
  if(missing(s2)) {
    warning("s2 not informed. Assuming s2 = s1.")
    s2<-s1
  }
  
  # Guarantee that diff_mu is expressed as a positive value
  if (diff_mu<0) {
    warning("Using abs(diff_mu)")
    diff_mu<-abs(diff_mu)
  }
  
  # Calculate required values based on the Zhang formula
  c       <- 0.5*exp(-7.06*diff_mu/tolmargin) # c factor
  sigma_e <- sqrt((s1^2+s2^2))                # combined variance
  talpha  <- qnorm(alpha)                     # initial value for iteration
  tbeta   <- qnorm((1-c)*beta)                # initial value for iteration
  n       <- 0                                # initial value for iteration
  rhs     <- (talpha+tbeta)^2 * (sigma_e/(tolmargin-diff_mu))^2
  
  while (n<rhs){
    n       <- rhs                  # update n
    nu      <- calc_df(s1,s2,n,n)   # calculate DoF (Welch)
    talpha  <- qt(alpha,nu)         # update t-quantile
    tbeta   <- qt((1-c)*beta,nu)    # update t-quantile
    rhs     <- (talpha+tbeta)^2 * (sigma_e/(tolmargin-diff_mu))^2
  }
  return(n)   # return required number of observations afor each group
}
```

```{r}
# Calcula o desvio padrão amostral das acurácias dos algoritmos
sd_as <- sqrt(s2_aScon_max)
sd_aP <- sqrt(s2_aPcon_max)

# Calcula o tamanho de amostras necessário
n_a<-ceiling(calcN_tost2(alpha = alpha, beta = 1-PI, diff_mu = (delta_a/2),
                         tolmargin = delta_a, s1 = sd_aP, s2 = sd_as))
cat("n_a =",n_a)
```

Assim, é necessário realizar noventa e quatro ($n_{new} = n_a - n_t$) novas amostragens para que o teste da acurácia seja realizado com o nível de potência desejada. O aplicativo [@campelo2016] é executado mais uma vez com um número de instâncias $n_{new}$. Admitindo que a nova execução do aplicativo é independente da execução inicial e que as características dos algoritmos não foi alterada, os resultados das novas instâncias podem ser simplesmente concatenados ao arquivo "*1991-09-15_8_30.csv*" (os novos dados compõem o conjunto de amostras total). Essa concatenação é realizada direto no arquivo *.csv* após a renomeação manual das instâncias para representarem corretamente a sequência já iniciada. Com isso, os dados iniciais são renomeados (*Inst01 - Inst08*) e os novos dados (*Inst1 - Inst94*) são concatenados ao final do arquivo original. A opção pelo ajuste manual ao invés de programar uma rotina computacional para realizar a concatenação de forma automatizada é justificada por se buscar manter um único arquivo *.csv* como base de dados.

```{r}
# Avalia as cento e duas instâncias definidas para o teste do tempo
dados_final <- head(dados_preteste,2*n_a*n_rep)
```

Com isso, o arquivo "*1991-09-15_8_30.csv*" passa a conter dados das cento e duas instâncias necessárias para o teste.

# Análise Exploratória dos Dados
Os dados são consolidados em um arquiv.o *.csv*. Tem-se para as $n_a$ instâncias definidas do teste de acurácia:

```{r}
dados_ac <- aggregate(Accuracy~Algorithm:Instance, data=dados_final, FUN=mean)
dados_ac <- droplevels(dados_ac)

dados_acP_plot <- dados_final[which(dados_final$Algorithm=="Proposed"),]
dados_acP_plot <- droplevels(dados_acP_plot)

dados_acS_plot <- dados_final[which(dados_final$Algorithm=="Standard"),]
dados_acS_plot <- droplevels(dados_acS_plot)

summary(dados_ac)
```

O *boxplot* das acurácias para as $n_{rep}$ execuções de cada algoritmo em cada instância é:

```{r, out.width = '950px', out.height='475px', fig.align='center', dpi=600, out.extra='angle=90'}
#caixas invisíveis / deslocar caixas esq. em -0.15 / deslocar caixas dir. em +0.15
boxplot(dados_ac$Accuracy~Instance, data = dados_ac, xlim = c(0.5, n_a+0.5),
        ylim = c(0.75, 1.0), boxfill=rgb(1, 1, 1, alpha=1), border=rgb(1, 1, 1, alpha=1)) 
boxplot(dados_acP_plot$Accuracy~Instance, data = dados_acP_plot, xaxt = "n",
        add = TRUE, boxfill="red", boxwex=0.25, at = 1:n_a - 0.15, border = "red")
boxplot(dados_acS_plot$Accuracy~Instance, data = dados_acS_plot, 
        main = "Acurácia: padrão original (azul) X propos. simplificado (vermelho)",
        xaxt = "n", add = TRUE, boxfill="blue", boxwex=0.25, at = 1:n_a + 0.15,
        border = "blue")
```


# Análise estatística

### Teste de hipóteses - acurácia
Como definido anteriormente para o caso da acurácia, optou-se por um teste de não-inferioridade (não é necessária verificar a equivalência da acurácia dos algoritmos). Portanto, o *teste-t* pareado unilateral inferior é suficiente para testar a hipótese já definida anteriormente. Assim, tem-se que:

$$\begin{cases} H_{a0}^a: \mu_{aP} - \mu_{aS} = -\delta_{a}^{*}  & \\ H_{a1}^a: \mu_{aP} - \mu_{aS} > -\delta_{a}^{*}\end{cases}$$


```{r}
with(dados_ac, 
     t.test(Accuracy~Algorithm, mu = -delta_a, paired=TRUE, alternative="greater", 
            conf.level = 1-alpha))
```

Como ($p_a^a>\alpha$), não é possível rejeitar a hipótese nula $H_{a0}^a$.

### Validação da premissa de normalidade das médias
Deseja-se verificar a premissa de normalidade das médias (diferenças) da acurácia através do teste de normalidade de Shapiro-Wilk [@campelo2015]. Para as diferenças de acurácia, tem-se:

```{r}
difAccuracy <- dados_ac$Accuracy[dados_ac$Algorithm=="Proposed"] - 
                        dados_ac$Accuracy[dados_ac$Algorithm=="Standard"]
shapiro.test(difAccuracy)
```

Para que a validação da premissa seja mais compreensiva, também serão apresentados os *qqplot* dessas diferenças.

```{r}
qqPlot(difAccuracy, pch=16, cex=1.5, las=1, main = "Diferenças de acurácia")
```

Considerando os *qqplot* apresentados e que o *valor-p* encontrado foi superior ao $\alpha_{norm}$ determinado para o teste, acredita-se que não há nenhum forte indício para rejeição da premissa de normalidade das médias da acurácia.

### Conclusões
Não é possível rejeitar a possibilidade do algoritmo simplificado proposto implicar em uma degradação considerável de acurácia. Tal afirmação é feita para um nível de potência superior à 80\%. A análise de potência foi realizada *a priori*, sendo que o tamanho amostral necessário para o teste foi calculado com base em um nível mínimo de potência desejada para o estudo. O tamanho de efeito prático foi de $\delta_a^{\ast}=0.03$ e o número de instâncias considerado no teste foi de $n_a=102$.


# Referências bibliográficas




